{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#sns.set_context(\"talk\")\n",
    "#rc('axes', labelsize=20, titlesize=20)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import math\n",
    "import scipy.stats as ss\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ABC_sample(priorSampler, likelihoodSimulator, summaryStatistics, epsilon, data, n): \n",
    "    # epsilon is the tolerance value\n",
    "    # data is a numpy.array (format), each element is one observation \n",
    "    # priorSampler and likelihoodSimulator return numpy.arrays, each element is a random variable\n",
    "    # summaryStatistics returns a 1-dim array\n",
    "    \n",
    "    # priorSampler - a function taking one argument: n - the desired length of the sample, it returns an np.array\n",
    "    # likelihoodSimulator - a function taking two argument: the desired number of observations and the current parameter, it returns an np.array \n",
    "    # summaryStatistics - a function taking one argument - data, returns a 1-dim array\n",
    "    # epsilon - currently a number, not percentage,\n",
    "    # data - an array\n",
    "    # n - number of accepted samples (NOT number of iterations)\n",
    "    \n",
    "    #OUTPUT:\n",
    "    #It returns a list where the first element is the dataframe (as ABC function)\n",
    "    #and the second element is the number of iterations needed to create the sample of required size n\n",
    "    \n",
    "    stat = summaryStatistics(data)\n",
    "    theta_generated = []\n",
    "    accepted = []\n",
    "    output_list = []\n",
    "    i = 0\n",
    "    niter = 0\n",
    "    iteration_time = []\n",
    "    \n",
    "    while True:\n",
    "        if (niter % 1000 == 0):\n",
    "            start_time = timeit.default_timer()\n",
    "        niter = niter+1\n",
    "        # simulate prior\n",
    "        simulated_prior = priorSampler(1)\n",
    "        # data is currently an array of shape (data_len,)\n",
    "        simulated_data = likelihoodSimulator(np.shape(data)[0], simulated_prior[0])\n",
    "        \n",
    "        temporary_stat = summaryStatistics(simulated_data)\n",
    "        # in the line below we are comparing sum of squares of the elements of temporary_stat - stat\n",
    "        if np.sum(np.square(np.subtract(temporary_stat, stat))) < epsilon*epsilon: # check here!\n",
    "            accept = 1\n",
    "            output_dict = {'accept': accept, 'z':simulated_data, 'theta': simulated_prior[0]} # added theta\n",
    "            # seems more reasonable to add the theta at the end of function ...\n",
    "            output_list.append(output_dict)\n",
    "            i = i+1\n",
    "        else: accept = 0         \n",
    "        \n",
    "        if (niter % 1000 == 0):\n",
    "            iteration_time.append(timeit.default_timer() - start_time)\n",
    "        \n",
    "        if i==n:\n",
    "            break\n",
    "    \n",
    "    df = pd.DataFrame(output_list)\n",
    "    return (df, niter, iteration_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_variance(values, weights):\n",
    "    #Return the weighted variance of values (a np.array)\n",
    "    average = numpy.average(values, weights=weights)\n",
    "    variance = numpy.average((values-average)**2, weights=weights)\n",
    "    variance = variance*len(values)/(len(values)-1) #Unbias estimator\n",
    "    return variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ABC_PMC(priorFunction, priorSampler, likelihoodSimulator, summaryStatistics, epsilon_array, data, n): \n",
    "    # ABC_PMC allows the user to set a decreasing sequence of tolerance levels. It returns the sample obtained with the last tolerance level.\n",
    "    \n",
    "    # epsilon_array is a numpy.array, it should be a decreasing sequence of tolerance values\n",
    "    # data is a numpy.array (format), each element is one observation \n",
    "    # priorSampler and likelihoodSimulator return numpy.arrays, each element is a random variable\n",
    "    # summaryStatistics returns a 1-dim array\n",
    "    \n",
    "    # priorFunction - a function taking one argument and returns the value of the pdf of the prior in that argument\n",
    "    # priorSampler - a function taking one argument: n - the desired length of the sample, it returns an np.array\n",
    "    # likelihoodSimulator - a function taking two argument: the desired number of observations and the current parameter, it returns an np.array \n",
    "    # summaryStatistics - a function taking one argument - data, returns a 1-dim array\n",
    "    # epsilon - currently a number, not percentage,\n",
    "    # data - an array\n",
    "    # n - number of accepted samples (NOT number of iterations! WATCH OUT)\n",
    "    \n",
    "    #OUTPUT:\n",
    "    #It returns a list where the first element is a list containing the parameters and pseudo-data\n",
    "    #obtained with the last tolerance leve.\n",
    "    #The second element is the number of iterations needed to create the sample of required size n\n",
    "    \n",
    "    iteration_time = []\n",
    "    \n",
    "    #Run basic ABC using the first tolerance level\n",
    "    temp = ABC_sample(priorSampler, likelihoodSimulator, summaryStatistics, epsilon_array[0], data , n)\n",
    "    df = temp[0]\n",
    "    niter = temp[1] #Number of iterations required for the initial step\n",
    "    weight_old = np.ones(n)*(1/n) #assign \"basic\" weights to the sampled parameters\n",
    "    theta_old = df.theta\n",
    "    sigma_squared = 2*weighted_variance(df.theta,weight_old) #Compute a weighted empirical variance of theta. Used as variance in the Gaussian kernel\n",
    "    \n",
    "    stat = summaryStatistics(data) #compute statistics of original data\n",
    "    output_list = []\n",
    "    \n",
    "    for t in range(1,len(epsilon_array)):\n",
    "        i = 0\n",
    "        theta_accepted = []\n",
    "        weight = []\n",
    "        sigma = sqrt(sigma_squared)\n",
    "        while True:\n",
    "            if (niter % 1000 == 0):\n",
    "                start_time = timeit.default_timer()\n",
    "            niter = niter+1\n",
    "            theta_star = np.random.choice(theta_old, size = 1, p=weight_old) #get one of the previous theta obtained at random (weighted)\n",
    "            simulated_prior = np.random.normal(loc = theta_star, scale = sigma, size = 1) #perturbate the choice\n",
    "            simulated_data = likelihoodSimulator(shape(data)[0], simulated_prior[0]) #simulate data\n",
    "            temporary_stat = summaryStatistics(simulated_data) #get statistics of simulated data\n",
    "            if np.sum(np.square(np.subtract(temporary_stat, stat))) < epsilon_array[t]*epsilon_array[t]:\n",
    "                #Accept!\n",
    "                theta_accepted.append(simulated_prior[0])\n",
    "                if t==(len(epsilon_array)-1): #last tolerance level, prepare output\n",
    "                    output_dict = {'z':simulated_data, 'theta': simulated_prior[0]} \n",
    "                    output_list.append(output_dict)\n",
    "                #Compute weight\n",
    "                #den = 0\n",
    "                #for j in range(0,n):\n",
    "                #    aux = (1/sigma)*(simulated_prior[0]-theta_old[j])\n",
    "                #    den = den + weight_old[j]*(1/sigma)*(1/sqrt(2*math.pi))*exp(-(aux)**2/2)\n",
    "                #weight.append(priorFunction(simulated_prior[0])/den)\n",
    "\n",
    "                #Faster way to compute weight\n",
    "                phi = np.true_divide(np.exp(-np.true_divide(np.power(np.true_divide(np.subtract(np.ones(n)*simulated_prior[0],theta_old),sigma),2),2)),sqrt(2*math.pi))\n",
    "                den_new = np.sum(np.true_divide(np.multiply(weight_old,phi),sigma))\n",
    "                weight.append(priorFunction(simulated_prior[0])/den_new)    \n",
    "                #End compute weight\n",
    "                \n",
    "                i = i+1\n",
    "                \n",
    "            if (niter % 1000 == 0 and 'start_time' in vars()):\n",
    "                iteration_time.append(timeit.default_timer() - start_time)\n",
    "            if i==n:\n",
    "                break\n",
    "        \n",
    "        weight = weight/np.sum(weight) #normalize weight so that the sum is 1\n",
    "        sigma_squared = 2*weighted_variance(theta_accepted,weight) #compute sigma given the new weights\n",
    "        weight_old = weight #save weight for next step\n",
    "        theta_old = theta_accepted\n",
    "        \n",
    "    df = pd.DataFrame(output_list)\n",
    "    return(df, niter, iteration_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######\n",
    "# set up for the normal ABC example\n",
    "######\n",
    "\n",
    "prior_mean = -3.0\n",
    "prior_sd = 3\n",
    "likelihood_sd = 1\n",
    "\n",
    "def NormalPriorFunction(x):\n",
    "    return ss.norm.pdf(x=x,loc=prior_mean, scale=prior_sd)\n",
    "\n",
    "def NormalPriorSampler(n):\n",
    "    return np.random.normal(loc=prior_mean, scale=prior_sd, size=n)\n",
    "\n",
    "def NormalLiklihoodSimulator(n, param):\n",
    "    #unknown mean\n",
    "    return np.random.normal(loc=param, scale=likelihood_sd, size=n)\n",
    "    \n",
    "def NormalSummary(data):\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "data = np.random.normal(loc=0,scale=likelihood_sd,size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######\n",
    "# compare ABC and ABC-PMC on the Normal Example\n",
    "######\n",
    "sample_size = 1000\n",
    "tolerance_seq = [1,0.5,0.1,0.01]\n",
    "res_ABC = ABC_sample(NormalPriorSampler, NormalLiklihoodSimulator, NormalSummary, tolerance_seq[-1], data , sample_size)\n",
    "res_ABCPMC = ABC_PMC(NormalPriorFunction,NormalPriorSampler, NormalLiklihoodSimulator, NormalSummary, tolerance_seq, data , sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations ABC:  658488\n",
      "Seconds required by 1000 iterations in ABC:  0.0289141538253\n",
      "Number of iterations ABC-PMC:  43568\n",
      "Seconds required by 1000 iterations in ABC PMC:  0.781949180167\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of iterations ABC: \",res_ABC[1])\n",
    "print(\"Seconds required by 1000 iterations in ABC: \",sum(res_ABC[2])/len(res_ABC[2]))\n",
    "print(\"Number of iterations ABC-PMC: \",res_ABCPMC[1])\n",
    "print(\"Seconds required by 1000 iterations in ABC PMC: \",sum(res_ABCPMC[2])/len(res_ABCPMC[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean estimator from ABC:  0.06057347353974272\n",
      "Mean estimator from ABC PMC:  0.0795063070235797\n"
     ]
    }
   ],
   "source": [
    "#Check estimate accuracy (it should be almost the same)\n",
    "print(\"Mean estimator from ABC: \",np.mean(res_ABC[0].theta))\n",
    "print(\"Mean estimator from ABC PMC: \",np.mean(res_ABCPMC[0].theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC requires  1.8135694782399514  seconds\n",
      "ABC-PMC requires  0.6459451373400225  seconds\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "sample_size = 100\n",
    "t = timeit.Timer(lambda: ABC_sample(NormalPriorSampler, NormalLiklihoodSimulator, NormalSummary, tolerance_seq[-1], data , sample_size))\n",
    "print(\"ABC requires \",(t.timeit(number=k))/k,\" seconds\")\n",
    "t2 = timeit.Timer(lambda: ABC_PMC(NormalPriorFunction,NormalPriorSampler, NormalLiklihoodSimulator, NormalSummary, tolerance_seq, data , sample_size))\n",
    "print(\"ABC-PMC requires \",(t2.timeit(number=k))/k,\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC requires  9.0751675368  seconds\n",
      "ABC-PMC requires  9.08014227724001  seconds\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "sample_size = 500\n",
    "t = timeit.Timer(lambda: ABC_sample(NormalPriorSampler, NormalLiklihoodSimulator, NormalSummary, tolerance_seq[-1], data , sample_size))\n",
    "print(\"ABC requires \",(t.timeit(number=k))/k,\" seconds\")\n",
    "t2 = timeit.Timer(lambda: ABC_PMC(NormalPriorFunction,NormalPriorSampler, NormalLiklihoodSimulator, NormalSummary, tolerance_seq, data , sample_size))\n",
    "print(\"ABC-PMC requires \",(t2.timeit(number=k))/k,\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC requires  18.202306089300038  seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-37ef2050398d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ABC requires \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mABC_PMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormalPriorFunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNormalPriorSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalLiklihoodSimulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalSummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ABC-PMC requires \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Giulio/anaconda/lib/python3.6/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Giulio/anaconda/lib/python3.6/timeit.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer, _stmt)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-37ef2050398d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mABC_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormalPriorSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalLiklihoodSimulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalSummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ABC requires \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mABC_PMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormalPriorFunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNormalPriorSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalLiklihoodSimulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalSummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ABC-PMC requires \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-cdb3bc502a09>\u001b[0m in \u001b[0;36mABC_PMC\u001b[0;34m(priorFunction, priorSampler, likelihoodSimulator, summaryStatistics, epsilon_array, data, n)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulated_prior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtheta_old\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                     \u001b[0mden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mden\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweight_old\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpriorFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulated_prior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m#End compute weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "sample_size = 1000\n",
    "t = timeit.Timer(lambda: ABC_sample(NormalPriorSampler, NormalLiklihoodSimulator, NormalSummary, tolerance_seq[-1], data , sample_size))\n",
    "print(\"ABC requires \",(t.timeit(number=k))/k,\" seconds\")\n",
    "t2 = timeit.Timer(lambda: ABC_PMC(NormalPriorFunction,NormalPriorSampler, NormalLiklihoodSimulator, NormalSummary, tolerance_seq, data , sample_size))\n",
    "print(\"ABC-PMC requires \",(t2.timeit(number=k))/k,\" seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
