{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import math\n",
    "import scipy.stats as ss\n",
    "from scipy import sparse\n",
    "\n",
    "from ABC_algorithm import ABC \n",
    "from ABC_algorithm import ABC \n",
    "\n",
    "#from post_adjusting_GK_corrected import PostProcessGK\n",
    "#from post_adjusting_GK_corrected import EpanechnikovKernel\n",
    "\n",
    "import statsmodels as sm\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EpanechnikovKernel(t,delta,c=1):\n",
    "    if t<=delta:\n",
    "        return c*(1/delta)*(1-(t/delta)**2)\n",
    "    else:\n",
    "        return 0\n",
    "def PostProcessGK(df, Summary, data, name_param = 'param1', q=0.5,  weighted=True):\n",
    "    df_accepted = df[df['accept'] == 1]\n",
    "    #print df_accepted.head\n",
    "    accepted_count = len(df_accepted.index)\n",
    "    #print accepted_count\n",
    "    #print shape(data)[0]\n",
    "    if accepted_count <= shape(data)[0]:\n",
    "        print accepted_count, \"is number of accepted thetas\"\n",
    "\n",
    "    if accepted_count < 2:\n",
    "        print \"Post processing failed; too few accepted values.\"\n",
    "\n",
    "    summary = GKSummary(data)\n",
    "\n",
    "    #print df_accepted.statistics\n",
    "    #print Summary\n",
    "\n",
    "    df_accepted.statistics_diff = df_accepted.statistics.apply(lambda x: np.subtract(x,summary))\n",
    "    #print df_accepted.statistics_diff\n",
    "    df_accepted.statistics_diff_abs = df_accepted.statistics_diff.apply(lambda x: np.power(np.sum(np.square(x)),0.5))\n",
    "    #print df_accepted.statistics_diff_abs.shape\n",
    "    #df_accepted.statistics_diff_abs.hist(bins=100)\n",
    "    quantile = df_accepted.statistics_diff_abs.quantile(0.5) # shouled be ok\n",
    "    #plt.show()\n",
    "    #create column with kernal transform\n",
    "    df_accepted.kernel = df_accepted.statistics_diff_abs.apply(lambda x: EpanechnikovKernel(x, delta=quantile)) #diff_abs\n",
    "\n",
    "    mod = LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "    #print type(df_accepted.statistics_diff)\n",
    "    #X = np.array(df_accepted.statistics_diff) #list of vector\n",
    "\n",
    "    #Create X\n",
    "    size = shape(data)[0] #find a clever way to compute this!!!\n",
    "    X = np.empty([accepted_count, size])\n",
    "    i = 0\n",
    "    for row in df_accepted.statistics_diff:\n",
    "        X[i,] = row\n",
    "        i += 1\n",
    "\n",
    "    #print X\n",
    "    #print type(X)\n",
    "    #print shape(X)  \n",
    "    #X = df_accepted.statistics_diff.as_matrix()\n",
    "    #X.shape = (shape(X)[0], len(data))  \n",
    "    #X = np.reshape(X, (shape(X)[0], 100))\n",
    "    # df.reset_index().values\n",
    "    y = np.array(df_accepted[name_param])\n",
    "    y.shape = (shape(y)[0],1)\n",
    "    #print shape(y)eemilka\n",
    "    \n",
    "    #print type(y)\n",
    "    #print y\n",
    "    weights = np.array(df_accepted.kernel)\n",
    "    if weighted:\n",
    "        res = mod.fit(X, y, sample_weight=weights)\n",
    "    else: \n",
    "        res = mod.fit(X, y)\n",
    "        \n",
    "    beta = res.coef_[0]\n",
    "   \n",
    "    beta.shape = (shape(beta)[0], 1)\n",
    "   \n",
    "    \n",
    "    part_res = np.matmul(X, beta)\n",
    "    #print shape(part_res)\n",
    "    #print shape(y)\n",
    "    res = np.subtract(y, part_res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SimulateGK(n, param):  #B>0, K>-1/2 #param is a vector of A, B, g, k\n",
    "    A, B, g, k = param[0], param[1], param[2], param[3]\n",
    "    u_values = np.random.uniform(low=0.0, high=1.0, size=n)\n",
    "    x_values = np.zeros(n)\n",
    "    for i in range(0,n):\n",
    "        x_values[i] = A + B*(1+0.8*(1-np.exp(-g*sc.stats.norm.ppf(u_values[i], 0, 1) )) /(1 + np.exp(-g*sc.stats.norm.ppf(u_values[i], 0, 1) ))) *np.power((1+ np.power(sc.stats.norm.ppf(u_values[i], 0, 1),2)),k)*(sc.stats.norm.ppf(u_values[i], 0, 1))    \n",
    "    return x_values\n",
    "\n",
    "\n",
    "param = [3,1,2,0.5]\n",
    "data = SimulateGK(10, param) # only 10 datapoints\n",
    "\n",
    "def GKPriorSampler(n): \n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.append(np.random.uniform(low=0.0, high=10.0, size=4)) # we assume uniform [1,10] prior for all 4 parameters\n",
    "    return l\n",
    "\n",
    "def GKLiklihoodSimulator(n, param):\n",
    "    #unknown mean\n",
    "    return SimulateGK(n, param)\n",
    "    \n",
    "def GKSummary(data):\n",
    "    return np.sort(data)  #The summary statistic is the identity function. No transformation on the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon_count = 2\n",
    "epsilon = 900\n",
    "epsilon_increment = 400\n",
    "\n",
    "k = 5\n",
    "n = 10000\n",
    "\n",
    "def calc_error(dist_from_truth, abc_post_means, epsilon, error_epsilon_list):\n",
    "    #print dist_from_truth\n",
    "    squared_dist_from_truth = np.power(dist_from_truth,2)\n",
    "    mse = np.mean(squared_dist_from_truth)\n",
    "    mse_err = 1.96*np.std(squared_dist_from_truth)\n",
    "\n",
    "    mc_bias = np.mean(dist_from_truth)\n",
    "    mc_bias_err = 1.96*np.std(dist_from_truth)\n",
    "\n",
    "    var = np.var(abc_post_means)\n",
    "\n",
    "    mse_check = np.add(var, np.power(mc_bias,2))\n",
    "\n",
    "    error_epsilon_list.append({'epsilon':epsilon,\n",
    "                               'bias':mc_bias, 'bias_err':mc_bias_err, \n",
    "                               'mse':mse, 'mse_err':mse_err,\n",
    "                               'var':var,\n",
    "                               'mse_check':mse_check\n",
    "                              })\n",
    "    return error_epsilon_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating MSE for different values of $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post mean 1.8372297268\n",
      "without_post_mean 4.99536847988\n",
      "post mean 1.8996642802\n",
      "without_post_mean 5.08789424246\n",
      "post mean 2.0892033485\n",
      "without_post_mean 5.07089182151\n",
      "post mean 2.0550718389\n",
      "without_post_mean 4.96249658047\n",
      "post mean 1.99443172837\n",
      "without_post_mean 5.04846547469\n",
      "post mean 2.45795645674\n",
      "without_post_mean 4.99574839147\n",
      "post mean 1.86098395534\n",
      "without_post_mean 4.95573966465\n",
      "post mean 1.77791196984\n",
      "without_post_mean 4.96758670484\n",
      "post mean 1.81466480801\n",
      "without_post_mean 4.9784016235\n",
      "post mean 1.55736594605\n",
      "without_post_mean 4.89611090955\n"
     ]
    }
   ],
   "source": [
    "# for param1\n",
    "post_mean = 3\n",
    "error_epsilon_list = []\n",
    "pp_error_epsilon_list = []\n",
    "\n",
    "for e in range(epsilon_count):\n",
    "    epsilon = epsilon + epsilon_increment\n",
    "    \n",
    "    #print \"epsilon:{}\".format(epsilon)\n",
    "\n",
    "    abc_post_means = []\n",
    "    pp_abc_post_means = []\n",
    "    dist_from_truth = []\n",
    "    pp_dist_from_truth = []\n",
    "\n",
    "    for i in range(k):\n",
    "        ## we will do abc k times for each epsilon\n",
    "        # print \"Iteration:{}\".format(i)\n",
    "        df_ei = ABC(GKPriorSampler, GKLiklihoodSimulator,GKSummary, epsilon, data, n)\n",
    "    \n",
    "        df_ei['param1'] = df_ei['theta'].apply(lambda x: x[0]) #selecting the FIRST parameter of the par list (A) \n",
    "                                                 #and assigning it to a new col of df\n",
    "        df_ei['param2'] = df_ei['theta'].apply(lambda x: x[1]) #selecting the SECOND parameter of the par list (B) \n",
    "                                                 #and assigning it to a new col of df\n",
    "        df_ei['param3'] = df_ei['theta'].apply(lambda x: x[2]) #selecting the SECOND parameter of the par list (G) \n",
    "                                                 #and assigning it to a new col of df\n",
    "        df_ei['param4'] = df_ei['theta'].apply(lambda x: x[3]) #selecting the SECOND parameter of the par list (k) \n",
    "                                             \n",
    "    \n",
    "        df_abc_accepted = df_ei[df_ei.accept == 1]\n",
    "        count_accepted = len(df_abc_accepted.index)\n",
    "        #print count_accepted\n",
    "        if count_accepted < 20:\n",
    "            #print \"Not doing post adjustment\"\n",
    "            pp_abc_post_means.append(np.nan)\n",
    "            pp_dist_from_truth.append(np.nan)\n",
    "        else:\n",
    "            ## also post process the ABC output\n",
    "            \n",
    "            df_abc_accepted_post_processed = PostProcessGK(df_ei, GKSummary, data, name_param = 'param1', weighted=True)\n",
    "            #df_abc_accepted_post_processed = df_ei\n",
    "            pp_abc_post_mean = df_abc_accepted_post_processed.mean()\n",
    "            pp_abc_post_means.append(pp_abc_post_mean)\n",
    "            print \"post mean\", pp_abc_post_mean\n",
    "            pp_dist_from_truth.append(abs(pp_abc_post_mean - post_mean))\n",
    "\n",
    "            ## store k abc posterior means w and w/out post processing (pp)\n",
    "        abc_post_mean = df_abc_accepted.param1.mean()\n",
    "        abc_post_means.append(abc_post_mean)\n",
    "        print \"without_post_mean\", abc_post_mean\n",
    "        ## and store dist of this from truth\n",
    "        dist_from_truth.append(abs(abc_post_mean - post_mean))\n",
    "        \n",
    "    error_epsilon_list = calc_error(dist_from_truth, abc_post_means, epsilon, error_epsilon_list)\n",
    "    pp_error_epsilon_list = calc_error(pp_dist_from_truth, pp_abc_post_means, epsilon, pp_error_epsilon_list)\n",
    "\n",
    "    \n",
    "mse_df = pd.DataFrame(error_epsilon_list)\n",
    "pp_mse_df = pd.DataFrame(pp_error_epsilon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bias  bias_err  epsilon       mse  mse_check   mse_err       var\n",
      "0  2.033023  0.092246     1300  4.135399   4.135399  0.373579  0.002215\n",
      "1  1.958717  0.066558     1700  3.837727   3.837727  0.258595  0.001153\n",
      "       bias  bias_err  epsilon       mse  mse_check   mse_err       var\n",
      "0  1.024880  0.184880     1300  1.059276   1.059276  0.383501  0.008898\n",
      "1  1.106223  0.589455     1700  1.314176   1.314176  1.132789  0.090446\n"
     ]
    }
   ],
   "source": [
    "print mse_df.head()\n",
    "print pp_mse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff804ff9ad0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEYCAYAAACnYrZxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4S4iEiCFu4hIgBTuIiIB+v/PGrPaVHacewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff804ff97d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=mse_df.epsilon, y=mse_df.mse, marker=\"+\", fit_reg=False, label='ABC')\n",
    "sns.regplot(x=pp_mse_df.epsilon, y=pp_mse_df.mse, marker=\"+\", fit_reg=False, label='ABC w/ post processing')\n",
    "#plt.errorbar(x=mse_df.epsilon, y=mse_df.mse, yerr=mse_df.mse_err, linestyle=\"None\")\n",
    "plt.xlabel(r'\\epsilon')\n",
    "plt.ylabel(r'MSE')\n",
    "plt.title(r'$n=1000, k=100$')\n",
    "plt.legend(loc='upper left')\n",
    "#plt.savefig('plots/gk_mse_epsilon.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
